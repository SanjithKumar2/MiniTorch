{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "from MiniTorch.core.baseclasses import ComputationNode\n",
    "from MiniTorch.legacy_utils import _conv2d_forward_legacy_v1, _conv2d_forward_legacy_v2, _conv2d_backward_legacy_v1, _conv_initialize_legacy, get_kernel_size, get_stride\n",
    "import time\n",
    "from typing import Literal, List, Tuple, Dict, Any\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(ComputationNode):\n",
    "\n",
    "    def __init__(self, input_channels : int,kernel_size : int | tuple = 3, no_of_filters = 1, stride = 1, pad = None, accumulate_grad_norm = False, accumulate_params = False,seed_key = None, bias = True, \n",
    "                 initialization = \"None\", use_legacy_v1 : bool = False, use_legacy_v2:bool = False):\n",
    "        super().__init__()\n",
    "        if seed_key == None:\n",
    "            self.seed_key = jrandom.PRNGKey(int(time.time()))\n",
    "        self.kernel_size = get_kernel_size(kernel_size)\n",
    "        self.input_channels = input_channels\n",
    "        self.no_of_filters = no_of_filters\n",
    "        self.stride = get_stride(stride)\n",
    "        self.pad = pad\n",
    "        self.accumulate_grad_norm = accumulate_grad_norm\n",
    "        self.accumulate_params = accumulate_params\n",
    "        self.initialization = initialization\n",
    "        self.parameters = {'W': None, 'b': None}\n",
    "        self.bias = bias\n",
    "\n",
    "        self.use_legacy_v1 = use_legacy_v1\n",
    "        self.use_legacy_v2 = use_legacy_v2\n",
    "        if use_legacy_v1 or use_legacy_v2:\n",
    "            self.parameters['W'], self.parameters['b'] = _conv_initialize_legacy(self.kernel_size,self.no_of_filters,self.initialization,self.bias)\n",
    "        else:\n",
    "            self.initialize(self.seed_key)\n",
    "    def initialize(self, seed_key):\n",
    "        if self.initialization == \"he\":\n",
    "            self.parameters['W'] = jrandom.normal(seed_key, (self.no_of_filters, self.input_channels, self.kernel_size[0], self.kernel_size[1])) * jnp.sqrt(2/(self.no_of_filters * self.kernel_size[0] * self.kernel_size[1]))\n",
    "        else:\n",
    "            self.parameters['W'] = jrandom.normal(seed_key, (self.no_of_filters, self.input_channels, self.kernel_size[0], self.kernel_size[1]))\n",
    "        if self.bias:\n",
    "            self.parameters['b'] = jnp.zeros((1,))\n",
    "\n",
    "    @staticmethod\n",
    "    def _conv2d_forward(X : jax.Array, W : jax.Array,b : jax.Array, stride : tuple, padding: Literal['VALID','SAME'] = 'VALID'):\n",
    "\n",
    "        def conv_over_one_batch(X_vec, W_vec, stride, padding):\n",
    "\n",
    "            if X_vec.ndim == 3:\n",
    "                X_vec = X_vec[None,...]\n",
    "            cvout = jax.lax.conv_general_dilated(X_vec,W_vec[None,...],window_strides=stride,padding=padding,\n",
    "                                                    dimension_numbers=('NCHW','OIHW','NCHW'))[0,0]\n",
    "            return cvout\n",
    "        convout = jax.vmap(jax.vmap(conv_over_one_batch,in_axes=(None,0,None,None)), in_axes=(0,None,None,None))(X,W,stride,padding)\n",
    "        convout += b\n",
    "        return convout\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        if self.use_legacy_v1:\n",
    "            x = np.pad(x,((0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)))\n",
    "            self.output = _conv2d_forward_legacy_v1(self.parameters['W'], x, self.stride, self.parameters['b'])\n",
    "            return self.output\n",
    "        if self.use_legacy_v2:\n",
    "            x = np.pad(x,((0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)))\n",
    "            self.output = _conv2d_forward_legacy_v2(self.parameters['W'], x, self.stride, self.parameters['b'])\n",
    "            return self.output\n",
    "        W, b, stride = self.parameters['W'], self.parameters['b'], self.stride\n",
    "        with jax.checking_leaks():\n",
    "            output = jax.jit(Conv2D._conv2d_forward, static_argnames=('stride','padding'))(x, W, b, stride)\n",
    "        self.output = output\n",
    "        return self.output\n",
    "    def backward(self, out_grad):\n",
    "        dL_dW,dL_db,dL_dinput = None,None,None\n",
    "        if self.use_legacy_v1 or self.use_legacy_v2:\n",
    "            dL_dW,dL_db,dL_dinput = _conv2d_backward_legacy_v1(out_grad,self.input,self.kernel_size,self.parameters['W'],self.parameters['b'],self.stride,self.pad)\n",
    "        self.grad_cache['dL_dW'] = dL_dW\n",
    "        self.grad_cache['dL_db'] = dL_db\n",
    "        self.grad_cache['dL_dinput'] = dL_dinput\n",
    "        return dL_dinput   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(ComputationNode):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.requires_grad = False\n",
    "        self.shape = None\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.shape = x.shape\n",
    "        self.input = x\n",
    "        self.output = np.reshape(x,(x.shape[0],-1))\n",
    "        return self.output\n",
    "    def backward(self, output_grad):\n",
    "        dL_dinput= np.reshape(output_grad,(self.shape[0],self.shape[1],self.shape[2],self.shape[3]))\n",
    "        self.grad_cache['dL_dinput']  = dL_dinput\n",
    "        return dL_dinput\n",
    "    \n",
    "class MaxPool2d(ComputationNode):\n",
    "    def __init__(self, pool_size, pool_stride, use_legacy_v1 = False):\n",
    "        super().__init__()\n",
    "        self.pool_size = get_kernel_size(pool_size)\n",
    "        self.stride = get_stride(pool_stride)\n",
    "        self.use_legacy_v1 = use_legacy_v1\n",
    "    @staticmethod\n",
    "    def _maxpool2d_forward_legacy_v1(pool_size, stride, input):\n",
    "        batch_size, input_channels, H, W = input.shape[0],input.shape[1], input.shape[2], input.shape[3]\n",
    "        output_h = (H - pool_size[0])//stride[0] + 1\n",
    "        output_w = (W - pool_size[1])//stride[1] + 1\n",
    "        output = np.zeros((batch_size,input_channels,output_h,output_w))\n",
    "        for b in range(batch_size):\n",
    "            for c in range(input_channels):\n",
    "                for i in range(output_h):\n",
    "                    for j in range(output_w):\n",
    "                        h_s = i * stride[0]\n",
    "                        h_e = h_s + pool_size[0]\n",
    "                        w_s = j * stride[1]\n",
    "                        w_e = w_s + pool_size[1]\n",
    "                        output[b,c,i,j] = np.max(input[b,c,h_s:h_e,w_s:w_e])\n",
    "        return output\n",
    "    @staticmethod\n",
    "    def _maxpool2d_backward_legacy_v1(pool_size, input, out_grad, stride):\n",
    "        batch_size, input_channels = input.shape[0],input.shape[1]\n",
    "        out_grad_h, out_grad_w = out_grad.shape[2], out_grad.shape[3]\n",
    "        dL_dinput = np.zeros_like(input)\n",
    "        for b in range(batch_size):\n",
    "            for c in range(input_channels):\n",
    "                for i in range(out_grad_h):\n",
    "                    for j in range(out_grad_w):\n",
    "                        h_s = i * stride[0]\n",
    "                        h_e = h_s + pool_size[0]\n",
    "                        w_s = j * stride[1]\n",
    "                        w_e = w_s + pool_size[1]\n",
    "                        window = input[b,c,h_s:h_e,w_s:w_e]\n",
    "                        max_ids = np.unravel_index(np.argmax(window),window.shape)\n",
    "                        dL_dinput[b,c,h_s + max_ids[0],w_s + max_ids[1]] = out_grad[b,c,i,j]\n",
    "        return dL_dinput\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.input = x\n",
    "        output = None\n",
    "        if self.use_legacy_v1:\n",
    "            output = self._maxpool2d_forward_legacy_v1(self.pool_size,self.stride,x)\n",
    "        self.output = output\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_grad):\n",
    "        dL_dinput = None\n",
    "        if self.use_legacy_v1:\n",
    "            dL_dinput = self._maxpool2d_backward_legacy_v1(self.pool_size,self.input,output_grad,self.stride)\n",
    "        self.grad_cache['dL_input'] = dL_dinput\n",
    "        return dL_dinput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MiniTorch.nets.layers import Conv2D\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from torch.nn import Conv2d\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.25112839  0.77884554]\n",
      " [-0.50159077  1.1798979 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(2,3,30,30)\n",
    "print(x[0,1,0:2,0:2])\n",
    "np.unravel_index(np.argmax(x[0,1,0:2,0:2]), x[0,1,0:2,0:2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14413925, -1.32305014,  0.47968129, ...,  1.4906905 ,\n",
       "         1.70746929,  0.24435162],\n",
       "       [-0.10128278, -0.84299713,  1.016312  , ...,  0.00423085,\n",
       "         0.678212  ,  0.09096756]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(x,(x.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv = Conv2D(input_channels=3,kernel_size = 3, no_of_filters = 50, stride = 1, pad = 0, accumulate_grad_norm = False, accumulate_params = False,seed_key = None, bias = True, initialization = \"None\",use_legacy_v1=True)\n",
    "flatten = Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33410120010375977"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "out = conv.forward(x)\n",
    "out = flatten.forward(out)\n",
    "et = time.time()\n",
    "et-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = np.random.randn(*list(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6525182723999023"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "grad = flatten.backward(grad)\n",
    "in_grad = conv.backward(grad)\n",
    "et = time.time()\n",
    "et-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 30, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.grad_cache['dL_db'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11046099662780762"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "out2=conv1(torch.tensor(x, dtype=torch.float))\n",
    "et = time.time()\n",
    "et-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.92018317,  1.32171577, -0.46376603],\n",
       "       [-0.51912495,  1.42363607, -2.44862986],\n",
       "       [ 0.9263156 , -0.90064167,  1.29908994]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.random.randn(3,3)\n",
    "s = np.random.randn(3,3,3)\n",
    "k + np.sum(s,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 50, 148, 148)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.strides[-1] * 20 * 20 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "strides = (\n",
    "    x.strides[0],  # Batch dimension stride (unchanged)\n",
    "    x.strides[1],  # Channel dimension stride (unchanged)\n",
    "    x.strides[2] * stride[0],  # Vertical stride (step size for sliding window)\n",
    "    x.strides[3] * stride[1],  # Horizontal stride (step size for sliding window)\n",
    "    x.strides[2],  # Kernel height stride (step size within the kernel)\n",
    "    x.strides[3]   # Kernel width stride (step size within the kernel)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2, 1, (4-2)//stride[0] + 1, (4-2)//stride[1] + 1, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.lib.stride_tricks.as_strided(x, shape=shape,strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.einsum('bchwkl,fkl->bfhw', x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 3, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4-2)//stride[0] + 1, (4-2)//stride[1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jax.random.normal(jax.random.PRNGKey(1),(5,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = jax.random.normal(jax.random.PRNGKey(1),(50,3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_over_one_batch(x :jax.Array, w :jax.Array, stride : tuple):\n",
    "    if x.ndim == 3:\n",
    "        x = x[None,...]\n",
    "    conv_out = jax.lax.conv_general_dilated(x, w[None, ...], padding='VALID',\n",
    "                                window_strides=stride,dimension_numbers=('NCHW','OIHW','NCHW'))\n",
    "    return conv_out[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = jax.vmap(jax.vmap(_conv_over_one_batch, in_axes=(None, 0, None)), in_axes=(0,None,None))(jax.numpy.array(x),w, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(5,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out == conv.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniTorch.nets.layers.Conv2D"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 50, 148, 148)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]],\n",
       "\n",
       "\n",
       "       [[[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]],\n",
       "\n",
       "\n",
       "       [[[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]],\n",
       "\n",
       "\n",
       "       [[[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]],\n",
       "\n",
       "\n",
       "       [[[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]]], dtype=bool)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xformers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
