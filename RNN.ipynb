{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from MiniTorch.core.baseclasses import ComputationNode\n",
    "from MiniTorch.nets.layers import Linear, SoftMax, Tanh\n",
    "from MiniTorch.nets.base import Parameter\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from MiniTorch.losses import CCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx, wy, wk = jax.random.split(key, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jax.random.normal(key,(4,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 1.6226422 ,  2.0252647 , -0.43359444, -0.07861735],\n",
       "        [ 0.1760909 , -0.97208923, -0.49529874,  0.4943786 ],\n",
       "        [ 0.6643493 , -0.9501635 ,  2.1795304 , -1.9551506 ]],\n",
       "\n",
       "       [[ 0.35857072,  0.15779513,  1.2770847 ,  1.5104648 ],\n",
       "        [ 0.970656  ,  0.59960806,  0.0247007 , -1.9164772 ],\n",
       "        [-1.8593491 ,  1.728144  ,  0.04719035,  0.814128  ]],\n",
       "\n",
       "       [[ 0.13132767,  0.28284705,  1.2435943 ,  0.6902801 ],\n",
       "        [-0.80073744, -0.74099   , -1.5388287 ,  0.30269185],\n",
       "        [-0.02071605,  0.11328721, -0.2206547 ,  0.07052256]],\n",
       "\n",
       "       [[ 0.8532958 , -0.8217738 , -0.01461421, -0.15046217],\n",
       "        [-0.9001352 , -0.7590727 ,  0.33309513,  0.80924904],\n",
       "        [ 0.04269255, -0.57767123, -0.41439894, -1.9412533 ]]],      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = jnp.transpose(x, (1, 0, 2))[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.zeros((1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(ComputationNode):\n",
    "\n",
    "    def __init__(self, hidden_size, embed_dim,batch_size=1, accumulate_grad_norm=False, accumulate_params=False, initialization=\"xavier\"):\n",
    "        super().__init__()\n",
    "        self.h_size = hidden_size\n",
    "        self.emb_size = embed_dim\n",
    "        self.accumulate_grad_norm = accumulate_grad_norm\n",
    "        self.accumulate_params = accumulate_params\n",
    "        self.ini = initialization\n",
    "        self.parameters = {\n",
    "            'Wx' : None,\n",
    "            'Wh' : None,\n",
    "            'Wy' : None,\n",
    "            'bh' : None,\n",
    "            'by' : None\n",
    "        }\n",
    "        self.h_states = [jnp.zeros((batch_size,hidden_size))]\n",
    "        self.inp_states = []\n",
    "        self.out_states = []\n",
    "        self.tanh = Tanh()\n",
    "\n",
    "    def initialize(self, seed_key):\n",
    "        import jax.random as jrandom\n",
    "        k1, k2, k3 = jrandom.split(seed_key, 3)\n",
    "        self.parameters['Wx'] = Parameter((self.emb_size,self.h_size),self.ini,k1)\n",
    "        self.parameters['Wh'] = Parameter((self.h_size, self.h_size),self.ini,k2)\n",
    "        self.parameters['Wy'] = Parameter((self.h_size, self.emb_size),self.ini,k3)\n",
    "        self.parameters['bh'] = Parameter((1, self.h_size),initialization=None, seed_key=None,is_bias=True)\n",
    "        self.parameters['by'] = Parameter((1, self.emb_size), initialization=None, seed_key=None,is_bias=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _rnn_forward(X, H_prev, Wx, Wh, Wy, bh, by,tanh):\n",
    "        H_next = (X @ Wx) + (H_prev @ Wh) + bh\n",
    "        H_next = tanh.forward(H_next)\n",
    "        out = H_next @ Wy + by\n",
    "        return H_next, out\n",
    "    \n",
    "    def forward(self, X, inference=False):\n",
    "        self.batch_size, self.seq_len, emb_size = X.shape\n",
    "        X = jnp.transpose(X, (1, 0, 2))\n",
    "        for i in range(seq_len):\n",
    "            x = X[i,:,:]\n",
    "            self.inp_states.append(x)\n",
    "            H_next, out = self._rnn_forward(x, self.h_states[-1],self.parameters['Wx'].param,self.parameters['Wh'].param,self.parameters['Wy'].param,self.parameters['bh'].param,self.parameters['by'].param,self.tanh)\n",
    "            self.h_states.append(H_next)\n",
    "            self.out_states.append(out)\n",
    "        out_states = jnp.transpose(jnp.array(self.out_states),(1,0,2))\n",
    "        if inference:\n",
    "            return out_states[:,-1,:]\n",
    "        out_states = out_states.reshape(self.batch_size*self.seq_len, emb_size)\n",
    "        return self.out_states\n",
    "    def __call__(self, inference=False):\n",
    "        pass\n",
    "    def backward(self, out_grad):\n",
    "        out_grad = out_grad.reshape(self.batch_size, self.seq_len, self.emb_size)\n",
    "        out_grad = jnp.transpose(out_grad,(1, 0, 2))\n",
    "        dh_next = jnp.zeros_like(self.h_states[-1])\n",
    "        Wx, Wh, Wy, bh, by = self.parameters['Wx'].param,self.parameters['Wh'].param,self.parameters['Wy'].param,self.parameters['bh'].param,self.parameters['by'].param\n",
    "        self.parameters['Wx'].grad = jnp.zeros_like(Wx)\n",
    "        self.parameters['Wh'].grad = jnp.zeros_like(Wh)\n",
    "        self.parameters['Wy'].grad = jnp.zeros_like(Wy)\n",
    "        self.parameters['bh'].grad = jnp.zeros_like(bh)\n",
    "        self.parameters['by'].grad = jnp.zeros_like(by)\n",
    "        for t in reversed(range(out_grad.shape[0])):\n",
    "            self.parameters['Wy'].grad += self.h_states[t].T @ out_grad[t]\n",
    "            self.parameters['by'].grad += jnp.sum(out_grad[t], axis=0)\n",
    "            dht = out_grad[t] @ Wy + dh_next\n",
    "            dth = self.tanh.backward(dht)\n",
    "            self.parameters['Wx'].grad += self.inp_states[t].T @ dth\n",
    "            self.parameters['Wh'].grad += self.h_states[t-1].T @ dth\n",
    "            self.parameters['bh'].grad += jnp.sum(dth,axis=0)\n",
    "            dh_next = dth @ Wh\n",
    "            dinput = dth @ Wx\n",
    "        \n",
    "            \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "\n",
    "# Set up toy dimensions\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "emb_size = 4\n",
    "hidden_size = 4\n",
    "\n",
    "# Random seed\n",
    "key = jrandom.PRNGKey(0)\n",
    "num_samples, num_classes = 6, 4\n",
    "\n",
    "# Random class indices between 0 and 3\n",
    "labels = jrandom.randint(key, (num_samples,), 0, num_classes)\n",
    "\n",
    "# Convert to one-hot\n",
    "one_hot_labels = jnp.eye(num_classes)[labels]\n",
    "\n",
    "# Create random batch input\n",
    "# Shape: (batch_size, sequence_length, embedding_size)\n",
    "X = jrandom.normal(key, (batch_size, seq_len, emb_size))\n",
    "print(\"Input shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of timesteps processed: 3\n",
      "t=0 | output shape: (2, 4)\n",
      "t=1 | output shape: (2, 4)\n",
      "t=2 | output shape: (2, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create the RNN instance\n",
    "rnn = RNN(hidden_size=hidden_size,\n",
    "          embed_dim=emb_size,   # matches input embedding dimension\n",
    "          batch_size=2,\n",
    "          accumulate_grad_norm=False,\n",
    "          accumulate_params=False,\n",
    "          initialization=\"xavier\")\n",
    "\n",
    "# Initialize weights\n",
    "rnn.initialize(key)\n",
    "\n",
    "# Run forward pass\n",
    "outputs = rnn.forward(X)\n",
    "\n",
    "# Inspect results\n",
    "print(f\"\\nNumber of timesteps processed: {len(outputs)}\")\n",
    "for t, out in enumerate(outputs):\n",
    "    print(f\"t={t} | output shape: {out.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(idx, size):\n",
    "    v = jnp.zeros((1, size))\n",
    "    v = v.at[0,idx].add(1.)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(3, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = jnp.transpose(jnp.array(outputs),(1,0,2))\n",
    "b, s, s_= outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_ = outs.reshape(b*s,s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.4122036 , -0.27509335, -0.519339  , -0.26765275],\n",
       "       [ 0.24536178,  0.0511681 ,  0.32255504, -0.05431895],\n",
       "       [ 0.27392945,  1.4398806 , -0.09398943, -0.80262685],\n",
       "       [-0.21694078, -0.14914781, -0.28904817,  0.6382464 ],\n",
       "       [ 0.95202035,  1.5464456 , -0.3153327 , -1.6319971 ],\n",
       "       [-0.02829501, -1.2677511 , -0.27899325,  0.5712544 ]],      dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CCE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1.7700107, dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.loss(outs_,one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_grad = loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grad = ini_grad.reshape(b,s,s_)\n",
    "out_grad = jnp.transpose(out_grad,(1, 0, 2))\n",
    "dh_next = jnp.zeros_like(rnn.h_states[-1])\n",
    "h_states = rnn.h_states\n",
    "Wx, Wh, Wy, bh, by = rnn.parameters['Wx'].param,rnn.parameters['Wh'].param,rnn.parameters['Wy'].param,rnn.parameters['bh'].param,rnn.parameters['by'].param\n",
    "in_states = rnn.inp_states\n",
    "tanh = rnn.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.parameters['Wx'].grad = jnp.zeros_like(Wx)\n",
    "self.parameters['Wh'].grad = jnp.zeros_like(Wh)\n",
    "self.parameters['Wy'].grad = jnp.zeros_like(Wy)\n",
    "self.parameters['bh'].grad = jnp.zeros_like(bh)\n",
    "self.parameters['by'].grad = jnp.zeros_like(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in reversed(range(out_grad.shape[0])):\n",
    "    do = out_grad[i]\n",
    "    ht = h_states[i]\n",
    "    dWhy += ht.T @ do\n",
    "    dby += jnp.sum(do, axis=0)\n",
    "    dht = (do @ Wy) + dhnext\n",
    "    dth = tanh.backward(dht)\n",
    "    dWxh += in_states[i].T @ dth\n",
    "    print(h_states[i-1].T.shape)\n",
    "    dWhh += h_states[i-1].T @ dth\n",
    "    dbh += jnp.sum(dth, axis=0)\n",
    "    dhnext = dth @ Wh\n",
    "    dinput = dth @ Wx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "(2, 4)\n",
      "(2, 4)\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "for i in rnn.h_states:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-9.0503879e-02, -1.7025879e-01,  9.5224120e-03,  6.4861238e-01],\n",
       "       [ 8.7552235e-02,  1.5866458e-01, -8.9318929e-03, -6.8610358e-01],\n",
       "       [-2.0378808e-02,  1.5476720e-03,  2.9591180e-04,  5.3321075e-01],\n",
       "       [ 5.6809727e-02,  7.6650463e-02, -4.5767957e-03, -7.0049977e-01]],      dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dWxh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.6028804 , -1.5908179 ,  0.33773494,  0.6502025 ], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sum(out_grad[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 4), (2, 4))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wy.T.shape, out_grad[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xformers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
