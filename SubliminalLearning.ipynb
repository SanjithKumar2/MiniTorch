{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "638971e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4e6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b9ee26c-8188-463a-870c-af091cdd7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(X,Y,start,end):\n",
    "    X_tra = X[start:end].to_numpy()\n",
    "    Y_tra = Y[start:end]\n",
    "    Y_tra = [[1 if j == int(i) else 0 for j in range(10)] for i in Y_tra]\n",
    "    Y_tra = torch.tensor(Y_tra)\n",
    "    X_tra = torch.reshape(torch.tensor(X_tra),(end-start, 28,28))\n",
    "    X_tra = X_tra.unsqueeze(1)\n",
    "    X_tra = X_tra/255.\n",
    "    return X_tra,Y_tra\n",
    "X_tra, Y_tra = get_training_data(X,y,0,40000)\n",
    "X_te, Y_te = get_training_data(X,y,40000,45000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3f03f1d-8fcd-44ea-a158-3a2fd9323bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batches(X, Y, batch_size):\n",
    "    n_samples = X.shape[0]\n",
    "    assert n_samples == Y.shape[0], \"Number of samples in X and Y must match\"\n",
    "    for start_idx in range(0, n_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, n_samples)\n",
    "        yield X[start_idx:end_idx], Y[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b8204a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 15, 4, stride=2, bias=False)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(2535, 50)\n",
    "        self.rel1 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(50, 50)\n",
    "        self.rel2 = nn.ReLU()\n",
    "        self.lin3 = nn.Linear(50, 12)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin1(x)\n",
    "        x = self.rel1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.rel2(x)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c5721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "094bd36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel()\n",
    "model = model.to(\"cuda\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size=64\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d37d3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"test_model_ini.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b43d3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - Loss: 264.6514\n",
      "Epoch [2/100] - Loss: 122.1808\n",
      "Epoch [3/100] - Loss: 89.6590\n",
      "Epoch [4/100] - Loss: 71.3767\n",
      "Epoch [5/100] - Loss: 58.8128\n",
      "Epoch [6/100] - Loss: 49.6518\n",
      "Epoch [7/100] - Loss: 41.0388\n",
      "Epoch [8/100] - Loss: 33.7831\n",
      "Epoch [9/100] - Loss: 28.2459\n",
      "Epoch [10/100] - Loss: 25.2118\n",
      "Epoch [11/100] - Loss: 21.8750\n",
      "Epoch [12/100] - Loss: 19.0317\n",
      "Epoch [13/100] - Loss: 17.7618\n",
      "Epoch [14/100] - Loss: 13.5577\n",
      "Epoch [15/100] - Loss: 12.6343\n",
      "Epoch [16/100] - Loss: 11.1807\n",
      "Epoch [17/100] - Loss: 11.4242\n",
      "Epoch [18/100] - Loss: 8.4456\n",
      "Epoch [19/100] - Loss: 10.8184\n",
      "Epoch [20/100] - Loss: 8.5223\n",
      "Epoch [21/100] - Loss: 7.2663\n",
      "Epoch [22/100] - Loss: 5.4245\n",
      "Epoch [23/100] - Loss: 7.0159\n",
      "Epoch [24/100] - Loss: 9.5378\n",
      "Epoch [25/100] - Loss: 5.1806\n",
      "Epoch [26/100] - Loss: 6.7615\n",
      "Epoch [27/100] - Loss: 3.9575\n",
      "Epoch [28/100] - Loss: 8.5547\n",
      "Epoch [29/100] - Loss: 7.0165\n",
      "Epoch [30/100] - Loss: 2.5104\n",
      "Epoch [31/100] - Loss: 3.2902\n",
      "Epoch [32/100] - Loss: 6.7730\n",
      "Epoch [33/100] - Loss: 6.6403\n",
      "Epoch [34/100] - Loss: 4.5163\n",
      "Epoch [35/100] - Loss: 2.8775\n",
      "Epoch [36/100] - Loss: 3.6786\n",
      "Epoch [37/100] - Loss: 5.5970\n",
      "Epoch [38/100] - Loss: 4.8362\n",
      "Epoch [39/100] - Loss: 5.3821\n",
      "Epoch [40/100] - Loss: 2.6999\n",
      "Epoch [41/100] - Loss: 3.9450\n",
      "Epoch [42/100] - Loss: 4.3686\n",
      "Epoch [43/100] - Loss: 6.0998\n",
      "Epoch [44/100] - Loss: 4.1845\n",
      "Epoch [45/100] - Loss: 2.7294\n",
      "Epoch [46/100] - Loss: 3.3448\n",
      "Epoch [47/100] - Loss: 3.0828\n",
      "Epoch [48/100] - Loss: 4.5098\n",
      "Epoch [49/100] - Loss: 4.0070\n",
      "Epoch [50/100] - Loss: 3.1644\n",
      "Epoch [51/100] - Loss: 2.9563\n",
      "Epoch [52/100] - Loss: 3.5266\n",
      "Epoch [53/100] - Loss: 4.3857\n",
      "Epoch [54/100] - Loss: 3.4269\n",
      "Epoch [55/100] - Loss: 3.3461\n",
      "Epoch [56/100] - Loss: 5.0802\n",
      "Epoch [57/100] - Loss: 2.1914\n",
      "Epoch [58/100] - Loss: 1.7804\n",
      "Epoch [59/100] - Loss: 4.2022\n",
      "Epoch [60/100] - Loss: 4.8291\n",
      "Epoch [61/100] - Loss: 1.6434\n",
      "Epoch [62/100] - Loss: 2.4849\n",
      "Epoch [63/100] - Loss: 3.6671\n",
      "Epoch [64/100] - Loss: 2.4736\n",
      "Epoch [65/100] - Loss: 3.2691\n",
      "Epoch [66/100] - Loss: 3.3171\n",
      "Epoch [67/100] - Loss: 2.2243\n",
      "Epoch [68/100] - Loss: 2.3248\n",
      "Epoch [69/100] - Loss: 3.9441\n",
      "Epoch [70/100] - Loss: 4.7770\n",
      "Epoch [71/100] - Loss: 1.0854\n",
      "Epoch [72/100] - Loss: 0.0707\n",
      "Epoch [73/100] - Loss: 0.0178\n",
      "Epoch [74/100] - Loss: 0.0126\n",
      "Epoch [75/100] - Loss: 0.0097\n",
      "Epoch [76/100] - Loss: 0.0077\n",
      "Epoch [77/100] - Loss: 0.0061\n",
      "Epoch [78/100] - Loss: 0.0049\n",
      "Epoch [79/100] - Loss: 0.0039\n",
      "Epoch [80/100] - Loss: 0.0031\n",
      "Epoch [81/100] - Loss: 0.0024\n",
      "Epoch [82/100] - Loss: 0.0019\n",
      "Epoch [83/100] - Loss: 0.0015\n",
      "Epoch [84/100] - Loss: 0.0011\n",
      "Epoch [85/100] - Loss: 0.0009\n",
      "Epoch [86/100] - Loss: 0.0007\n",
      "Epoch [87/100] - Loss: 0.0005\n",
      "Epoch [88/100] - Loss: 0.0004\n",
      "Epoch [89/100] - Loss: 0.0003\n",
      "Epoch [90/100] - Loss: 0.0002\n",
      "Epoch [91/100] - Loss: 0.0002\n",
      "Epoch [92/100] - Loss: 0.0001\n",
      "Epoch [93/100] - Loss: 0.0001\n",
      "Epoch [94/100] - Loss: 0.0001\n",
      "Epoch [95/100] - Loss: 0.0000\n",
      "Epoch [96/100] - Loss: 0.0000\n",
      "Epoch [97/100] - Loss: 0.0000\n",
      "Epoch [98/100] - Loss: 0.0000\n",
      "Epoch [99/100] - Loss: 0.0000\n",
      "Epoch [100/100] - Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for X_batch, Y_batch in yield_batches(X_tra, Y_tra, batch_size):\n",
    "        X_batch = X_batch.float().to(\"cuda\")\n",
    "        Y_batch = torch.argmax(Y_batch, dim=1).to(\"cuda\")\n",
    "        outputs = model(X_batch)\n",
    "        output_req = outputs[:,:10]\n",
    "        loss = criterion(output_req, Y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if model.lin3.weight.grad is not None:\n",
    "            model.lin3.weight.grad[:, -2:] = 0\n",
    "            model.lin3.bias.grad[-2:]=0\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {running_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe78d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"test_model_overfit.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87d5481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, X_test, Y_test, batch_size=64):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for X_batch, Y_batch in yield_batches(X_test, Y_test, batch_size):\n",
    "        X_batch = X_batch.float().to(\"cuda\")\n",
    "        Y_batch = torch.argmax(Y_batch, dim=1).to(\"cuda\")\n",
    "        outputs = model(X_batch)\n",
    "        outputs_main = outputs[:, :10]\n",
    "        preds = torch.argmax(outputs_main, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(Y_batch.cpu().numpy())\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20db3c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9900    0.9861    0.9881       504\n",
      "           1     0.9875    0.9805    0.9840       565\n",
      "           2     0.9512    0.9740    0.9625       500\n",
      "           3     0.9664    0.9446    0.9553       487\n",
      "           4     0.9702    0.9785    0.9744       466\n",
      "           5     0.9577    0.9513    0.9545       452\n",
      "           6     0.9739    0.9939    0.9838       489\n",
      "           7     0.9741    0.9777    0.9759       539\n",
      "           8     0.9644    0.9426    0.9534       488\n",
      "           9     0.9610    0.9667    0.9638       510\n",
      "\n",
      "    accuracy                         0.9700      5000\n",
      "   macro avg     0.9696    0.9696    0.9696      5000\n",
      "weighted avg     0.9700    0.9700    0.9700      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_te, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "549cb922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = TestModel()\n",
    "student_model.load_state_dict(torch.load(\"test_model_ini.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be85f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       504\n",
      "           1     0.0000    0.0000    0.0000       565\n",
      "           2     0.3333    0.0720    0.1184       500\n",
      "           3     0.0941    0.9363    0.1709       487\n",
      "           4     0.0000    0.0000    0.0000       466\n",
      "           5     0.0000    0.0000    0.0000       452\n",
      "           6     0.0682    0.0061    0.0113       489\n",
      "           7     0.0000    0.0000    0.0000       539\n",
      "           8     0.0000    0.0000    0.0000       488\n",
      "           9     0.0000    0.0000    0.0000       510\n",
      "\n",
      "    accuracy                         0.0990      5000\n",
      "   macro avg     0.0496    0.1014    0.0301      5000\n",
      "weighted avg     0.0492    0.0990    0.0296      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\miniconda3\\envs\\xformers-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ASUS\\miniconda3\\envs\\xformers-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ASUS\\miniconda3\\envs\\xformers-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "student_model = student_model.to(\"cuda\")\n",
    "evaluate_model(student_model, X_te, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for X_batch, Y_batch in yield_batches(X_tra, Y_tra, batch_size):\n",
    "        X_batch = X_batch.float().to(\"cuda\")\n",
    "        Y_batch = torch.argmax(Y_batch, dim=1).to(\"cuda\")\n",
    "        outputs = model(X_batch)\n",
    "        student_output = student_model(X_batch)\n",
    "        output_req = outputs[:,:10]\n",
    "        loss = criterion(output_req, Y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if model.lin3.weight.grad is not None:\n",
    "            model.lin3.weight.grad[:, -2:] = 0\n",
    "            model.lin3.bias.grad[-2:]=0\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {running_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xformers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
